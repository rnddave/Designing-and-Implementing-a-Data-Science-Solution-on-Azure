{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Scaling\n",
        "Normalizing or standardizing are very similar techniques that change the range of values that a feature has. Doing so helps models learn faster and more robustly. \n",
        "\n",
        "Both of these processes are commonly referred to as *feature scaling*.\n",
        "\n",
        "In this exercise we'll use a dog training dataset to predict how many rescues a dog will perform on a given year, based on how old they were when their training began.\n",
        "\n",
        "We will train models with and without feature scaling and compare their behavior and results.\n",
        "\n",
        "But first, let's load our dataset and inspect it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-28 11:42:18--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21511 (21K) [text/plain]\n",
            "Saving to: ‘graphing.py’\n",
            "\n",
            "graphing.py         100%[===================>]  21.01K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-11-28 11:42:18 (21.4 MB/s) - ‘graphing.py’ saved [21511/21511]\n",
            "\n",
            "--2022-11-28 11:42:19--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/dog-training.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 974 [text/plain]\n",
            "Saving to: ‘dog-training.csv’\n",
            "\n",
            "dog-training.csv    100%[===================>]     974  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-28 11:42:19 (84.4 MB/s) - ‘dog-training.csv’ saved [974/974]\n",
            "\n",
            "--2022-11-28 11:42:19--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/m1b_gradient_descent.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2986 (2.9K) [text/plain]\n",
            "Saving to: ‘m1b_gradient_descent.py’\n",
            "\n",
            "m1b_gradient_descen 100%[===================>]   2.92K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-28 11:42:20 (30.3 MB/s) - ‘m1b_gradient_descent.py’ saved [2986/2986]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month_old_when_trained</th>\n",
              "      <th>mean_rescues_per_year</th>\n",
              "      <th>age_last_year</th>\n",
              "      <th>weight_last_year</th>\n",
              "      <th>rescues_last_year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68</td>\n",
              "      <td>21.1</td>\n",
              "      <td>9</td>\n",
              "      <td>14.5</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>14.9</td>\n",
              "      <td>5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>20.5</td>\n",
              "      <td>6</td>\n",
              "      <td>17.7</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>19.4</td>\n",
              "      <td>1</td>\n",
              "      <td>13.7</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>24.9</td>\n",
              "      <td>4</td>\n",
              "      <td>18.4</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   month_old_when_trained  mean_rescues_per_year  age_last_year  \\\n",
              "0                      68                   21.1              9   \n",
              "1                      53                   14.9              5   \n",
              "2                      41                   20.5              6   \n",
              "3                       3                   19.4              1   \n",
              "4                       4                   24.9              4   \n",
              "\n",
              "   weight_last_year  rescues_last_year  \n",
              "0              14.5                 35  \n",
              "1              14.0                 30  \n",
              "2              17.7                 34  \n",
              "3              13.7                 29  \n",
              "4              18.4                 30  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/dog-training.csv\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/m1b_gradient_descent.py\n",
        "data = pandas.read_csv(\"dog-training.csv\", delimiter=\"\\t\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset above tells us at what age a dog began training, how many rescues, on average, they have performed per year, and other stats, like what age they were last year, their weight and how many rescues they performed in that period.\n",
        "\n",
        "Note that we also have variables expressed in different units, such as  `month_old_when_trained` in months, `age_last_year` in years, and `weight_last_year` in kilograms.\n",
        "\n",
        "Having features in widely different ranges and units is a good indicator that a model can benefit from feature scaling.\n",
        "\n",
        "First, let's train our model using the dataset \"as is\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'plotly'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mm1b_gradient_descent\u001b[39;00m \u001b[39mimport\u001b[39;00m gradient_descent\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgraphing\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Train model using Gradient Descent\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# This method uses custom code that will print out progress as training advances.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# You don't need to inspect how this works for these exercises, but if you are\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# curious, you can find it in out GitHub repository\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m gradient_descent(data\u001b[39m.\u001b[39mmonth_old_when_trained, data\u001b[39m.\u001b[39mmean_rescues_per_year, learning_rate\u001b[39m=\u001b[39m\u001b[39m5E-4\u001b[39m, number_of_iterations\u001b[39m=\u001b[39m\u001b[39m8000\u001b[39m)\n",
            "File \u001b[0;32m~/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/graphing.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfromnumeric\u001b[39;00m \u001b[39mimport\u001b[39;00m repeat, shape\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexpress\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpx\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph_objects\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgraph_objects\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
          ]
        }
      ],
      "source": [
        "from m1b_gradient_descent import gradient_descent\n",
        "import numpy\n",
        "import graphing\n",
        "\n",
        "# Train model using Gradient Descent\n",
        "# This method uses custom code that will print out progress as training advances.\n",
        "# You don't need to inspect how this works for these exercises, but if you are\n",
        "# curious, you can find it in out GitHub repository\n",
        "model = gradient_descent(data.month_old_when_trained, data.mean_rescues_per_year, learning_rate=5E-4, number_of_iterations=8000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Analysis\n",
        "As you can see in the output above we're printing an estimate of weights and the calculated cost at each iteration.\n",
        "\n",
        "The final line in the output shows that the model stopped training because it reached its maximum allowed number of iterations, but the cost could still be lower if we had let it run longer.\n",
        "\n",
        "Let's plot the model at the end of this training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'graphing' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Plot the data and trendline after training\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m graphing\u001b[39m.\u001b[39mscatter_2D(data, \u001b[39m\"\u001b[39m\u001b[39mmonth_old_when_trained\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmean_rescues_per_year\u001b[39m\u001b[39m\"\u001b[39m, trendline\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mpredict)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'graphing' is not defined"
          ]
        }
      ],
      "source": [
        "# Plot the data and trendline after training\n",
        "graphing.scatter_2D(data, \"month_old_when_trained\", \"mean_rescues_per_year\", trendline=model.predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The plot above tells us that the younger a dog begins training, the more rescues it be perform in a year.\n",
        "\n",
        "Notice that it doesn't fit the data very well (most points are above the line). That's due to training being cut off early, before the model could find the optimal weights.\n",
        "\n",
        "\n",
        "## Standardizing data\n",
        "Let's use *standardization* as the form of *feature scaling* for this model, applying it to the `month_old_when_trained` feature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month_old_when_trained</th>\n",
              "      <th>mean_rescues_per_year</th>\n",
              "      <th>age_last_year</th>\n",
              "      <th>weight_last_year</th>\n",
              "      <th>rescues_last_year</th>\n",
              "      <th>standardized_age_when_trained</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68</td>\n",
              "      <td>21.1</td>\n",
              "      <td>9</td>\n",
              "      <td>14.5</td>\n",
              "      <td>35</td>\n",
              "      <td>1.537654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>14.9</td>\n",
              "      <td>5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>30</td>\n",
              "      <td>0.826655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>20.5</td>\n",
              "      <td>6</td>\n",
              "      <td>17.7</td>\n",
              "      <td>34</td>\n",
              "      <td>0.257856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>19.4</td>\n",
              "      <td>1</td>\n",
              "      <td>13.7</td>\n",
              "      <td>29</td>\n",
              "      <td>-1.543342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>24.9</td>\n",
              "      <td>4</td>\n",
              "      <td>18.4</td>\n",
              "      <td>30</td>\n",
              "      <td>-1.495942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   month_old_when_trained  mean_rescues_per_year  age_last_year  \\\n",
              "0                      68                   21.1              9   \n",
              "1                      53                   14.9              5   \n",
              "2                      41                   20.5              6   \n",
              "3                       3                   19.4              1   \n",
              "4                       4                   24.9              4   \n",
              "\n",
              "   weight_last_year  rescues_last_year  standardized_age_when_trained  \n",
              "0              14.5                 35                       1.537654  \n",
              "1              14.0                 30                       0.826655  \n",
              "2              17.7                 34                       0.257856  \n",
              "3              13.7                 29                      -1.543342  \n",
              "4              18.4                 30                      -1.495942  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add the standardized verions of \"age_when_trained\" to the dataset.\n",
        "# Notice that it \"centers\" the mean age around 0\n",
        "data[\"standardized_age_when_trained\"] = (data.month_old_when_trained - numpy.mean(data.month_old_when_trained)) / (numpy.std(data.month_old_when_trained))\n",
        "\n",
        "# Print a sample of the new dataset\n",
        "data[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice the the values `standardized_age_when_trained` column above are distributed in a much smaller range (between -2 and 2) and have their mean centered around `0`.\n",
        "\n",
        "## Visualizing Scaled Features\n",
        "Let's use a box plot to compare the original feature values to their standardized versions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'plotly'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msubplots\u001b[39;00m \u001b[39mimport\u001b[39;00m make_subplots\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph_objects\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgo\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexpress\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpx\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
          ]
        }
      ],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.box(data,y=[\"month_old_when_trained\", \"standardized_age_when_trained\"])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now compare the two features by hovering your mouse over the graph. You will see that:\n",
        "\n",
        " - `month_old_when_trained` ranges from 1 to 71 and has its median centered around 35.\n",
        "\n",
        " - `standardized_age_when_trained` ranges from -1.6381 to 1.6798, and is centered exactly at 0.\n",
        "\n",
        "## Training with standardized features\n",
        "We can now retrain our model using the standardized feature in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0  Current estimate: y = -0.002469271695567481 * x + 0.01989 Cost: 409.47558290398973\n",
            "Iteration 100  Current estimate: y = -0.23732823396711047 * x + 1.9116805097144178 Cost: 336.7707406040323\n",
            "Iteration 200  Current estimate: y = -0.4498267787096775 * x + 3.623357706888266 Cost: 277.25100655774355\n",
            "Iteration 300  Current estimate: y = -0.6420937932658433 * x + 5.172069793284766 Cost: 228.52524594986943\n",
            "Iteration 400  Current estimate: y = -0.8160554781852589 * x + 6.573332327196407 Cost: 188.63595906277715\n",
            "Iteration 500  Current estimate: y = -0.9734546445990158 * x + 7.841183663924317 Cost: 155.98064104392154\n",
            "Iteration 600  Current estimate: y = -1.1158681743324268 * x + 8.988325597103357 Cost: 129.24740317153262\n",
            "Iteration 700  Current estimate: y = -1.2447228176779617 * x + 10.026250609868582 Cost: 107.3622692791277\n",
            "Iteration 800  Current estimate: y = -1.3613094870961393 * x + 10.965357010711452 Cost: 89.44603003512722\n",
            "Iteration 900  Current estimate: y = -1.4667961900438484 * x + 11.8150531074983 Cost: 74.77892174936702\n",
            "Iteration 1000  Current estimate: y = -1.5622397304958524 * x + 12.583851463304212 Cost: 62.77171071939301\n",
            "Iteration 1100  Current estimate: y = -1.648596296389555 * x + 13.279454178351335 Cost: 52.94202146440177\n",
            "Iteration 1200  Current estimate: y = -1.7267310390618837 * x + 13.908830052436938 Cost: 44.89495786166459\n",
            "Iteration 1300  Current estimate: y = -1.7974267406485578 * x + 14.478284400892429 Cost: 38.30723866254353\n",
            "Iteration 1400  Current estimate: y = -1.8613916562788748 * x + 14.993522223514702 Cost: 32.91421005124923\n",
            "Iteration 1500  Current estimate: y = -1.9192666096319775 * x + 15.459705359319308 Cost: 28.49921349126829\n",
            "Iteration 1600  Current estimate: y = -1.9716314129404362 * x + 15.88150419971215 Cost: 24.884881725287755\n",
            "Iteration 1700  Current estimate: y = -2.019010675759084 * x + 16.263144478161262 Cost: 21.92601325572035\n",
            "Iteration 1800  Current estimate: y = -2.0618790606934327 * x + 16.608449605124303 Cost: 19.503739046527773\n",
            "Iteration 1900  Current estimate: y = -2.100666038741482 * x + 16.920878972358576 Cost: 17.520747100495903\n",
            "Iteration 2000  Current estimate: y = -2.135760191889627 * x + 17.203562610359846 Cost: 15.897373065011378\n",
            "Iteration 2100  Current estimate: y = -2.1675131060676733 * x + 17.459332546140928 Cost: 14.568399811055967\n",
            "Iteration 2200  Current estimate: y = -2.1962428934639444 * x + 17.69075117550343 Cost: 13.480437412296949\n",
            "Iteration 2300  Current estimate: y = -2.2222373794883374 * x + 17.90013693404643 Cost: 12.589778268036145\n",
            "Iteration 2400  Current estimate: y = -2.245756986311467 * x + 18.089587524093606 Cost: 11.860641202122501\n",
            "Iteration 2500  Current estimate: y = -2.2670373418682375 * x + 18.26100093023434 Cost: 11.263733996582848\n",
            "Iteration 2600  Current estimate: y = -2.2862916404637894 * x + 18.41609443402049 Cost: 10.775076611460438\n",
            "Iteration 2700  Current estimate: y = -2.3037127786312275 * x + 18.55642181831455 Cost: 10.375037815113883\n",
            "Iteration 2800  Current estimate: y = -2.319475287638908 * x + 18.683388933648818 Cost: 10.04754652273875\n",
            "Iteration 2900  Current estimate: y = -2.3337370820078647 * x + 18.798267782544944 Cost: 9.779446159571398\n",
            "Iteration 3000  Current estimate: y = -2.3466410415566474 * x + 18.902209262895628 Cost: 9.559966111081634\n",
            "Iteration 3100  Current estimate: y = -2.3583164428230607 * x + 18.996254698076292 Cost: 9.380289026291589\n",
            "Iteration 3200  Current estimate: y = -2.368880254203313 * x + 19.081346269299672 Cost: 9.233196591144043\n",
            "Iteration 3300  Current estimate: y = -2.378438307783756 * x + 19.158336454728143 Cost: 9.112779541285361\n",
            "Iteration 3400  Current estimate: y = -2.3870863596050333 * x + 19.22799656990864 Cost: 9.014200264369299\n",
            "Iteration 3500  Current estimate: y = -2.3949110489807546 * x + 19.291024495090983 Cost: 8.93349845471112\n",
            "Iteration 3600  Current estimate: y = -2.401990766481511 * x + 19.34805166684485 Cost: 8.867432012697625\n",
            "Iteration 3700  Current estimate: y = -2.4083964392799797 * x + 19.399649404019865 Cost: 8.813346797275454\n",
            "Iteration 3800  Current estimate: y = -2.4141922417250155 * x + 19.44633463142465 Cost: 8.769069998977995\n",
            "Iteration 3900  Current estimate: y = -2.419436238263504 * x + 19.488575058566685 Cost: 8.73282284987875\n",
            "Iteration 4000  Current estimate: y = -2.424180965151019 * x + 19.526793865335563 Cost: 8.703149163696683\n",
            "Iteration 4100  Current estimate: y = -2.428473956779045 * x + 19.56137394157209 Cost: 8.678856835237426\n",
            "Iteration 4200  Current estimate: y = -2.4323582218917084 * x + 19.592661722997484 Cost: 8.658969948978951\n",
            "Iteration 4300  Current estimate: y = -2.4358726744629524 * x + 19.620970661931807 Cost: 8.642689572821464\n",
            "Iteration 4400  Current estimate: y = -2.4390525235508185 * x + 19.646584367572686 Cost: 8.629361661936676\n",
            "Iteration 4500  Current estimate: y = -2.4419296260345265 * x + 19.669759447295053 Cost: 8.618450783291436\n",
            "Iteration 4600  Current estimate: y = -2.444532805768227 * x + 19.690728077436592 Cost: 8.609518605259927\n",
            "Iteration 4700  Current estimate: y = -2.4468881423488047 * x + 19.709700329324388 Cost: 8.60220628816974\n",
            "Iteration 4800  Current estimate: y = -2.449019232390721 * x + 19.72686627384553 Cost: 8.59622006834308\n",
            "Iteration 4900  Current estimate: y = -2.450947425925441 * x + 19.742397885646056 Cost: 8.591319456488982\n",
            "Iteration 5000  Current estimate: y = -2.4526920402937717 * x + 19.756450766035165 Cost: 8.5873075763309\n",
            "Iteration 5100  Current estimate: y = -2.4542705536739753 * x + 19.769165701855563 Cost: 8.584023255335477\n",
            "Iteration 5200  Current estimate: y = -2.4556987801844965 * x + 19.780670075936904 Cost: 8.581334549796948\n",
            "Iteration 5300  Current estimate: y = -2.4569910283155174 * x + 19.791079143263175 Cost: 8.579133444155014\n",
            "Iteration 5400  Current estimate: y = -2.4581602442765864 * x + 19.800497185638758 Cost: 8.577331511597684\n",
            "Iteration 5500  Current estimate: y = -2.4592181416964425 * x + 19.80901855642137 Cost: 8.575856361618827\n",
            "Iteration 5600  Current estimate: y = -2.4601753189743794 * x + 19.816728625788134 Cost: 8.57464873181533\n",
            "Iteration 5700  Current estimate: y = -2.461041365458852 * x + 19.82370463600485 Cost: 8.573660107090257\n",
            "Model training complete after 5700 iterations\n"
          ]
        }
      ],
      "source": [
        "# Let's retrain our model, this time using the standardized feature\n",
        "model_norm = gradient_descent(data.standardized_age_when_trained, data.mean_rescues_per_year, learning_rate=5E-4, number_of_iterations=8000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Let's take a look at that output again.\n",
        "\n",
        "Despite still being allowed a maximum of 8000 iterations, the model stopped at the 5700 mark.\n",
        "\n",
        "Why? Because this time, using the standardized feature, it was quickly able to reach a point where the cost could no longer be improved.\n",
        "\n",
        "In other words, it \"converged\" much faster than the previous version.\n",
        "\n",
        "## Plotting the standardized model\n",
        "\n",
        "We can now plot the new model and see the results of standardization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'graphing' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Plot the data and trendline again, after training with standardized feature\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m graphing\u001b[39m.\u001b[39mscatter_2D(data, \u001b[39m\"\u001b[39m\u001b[39mstandardized_age_when_trained\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmean_rescues_per_year\u001b[39m\u001b[39m\"\u001b[39m, trendline\u001b[39m=\u001b[39mmodel_norm\u001b[39m.\u001b[39mpredict)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'graphing' is not defined"
          ]
        }
      ],
      "source": [
        "# Plot the data and trendline again, after training with standardized feature\n",
        "graphing.scatter_2D(data, \"standardized_age_when_trained\", \"mean_rescues_per_year\", trendline=model_norm.predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It looks like this model fits the data much better that the first one!\n",
        "\n",
        "The standardized model shows a larger slope and data now centered on `0` on the X-axis, both factors which should allow the model to converge faster.\n",
        "\n",
        "But how much faster?\n",
        "\n",
        "Let's plot a comparison between models to visualize the improvements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cost1 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcost_history\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cost2 \u001b[39m=\u001b[39m model_norm\u001b[39m.\u001b[39mcost_history\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dickinsd/Github/Designing-and-Implementing-a-Data-Science-Solution-on-Azure/05-refine-and-test-ml-models/5-3-exercise-feature-normalization.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Creates dataframes with the cost history for each model\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "cost1 = model.cost_history\n",
        "cost2 = model_norm.cost_history\n",
        "\n",
        "# Creates dataframes with the cost history for each model\n",
        "df1 = pandas.DataFrame({\"cost\": cost1, \"Model\":\"No feature scaling\"})\n",
        "df1[\"number of iterations\"] = df1.index + 1\n",
        "df2 = pandas.DataFrame({\"cost\": cost2, \"Model\":\"With feature scaling\"})\n",
        "df2[\"number of iterations\"] = df2.index + 1\n",
        "\n",
        "# Concatenate dataframes into a single one that we can use in our plot\n",
        "df = pandas.concat([df1, df2])\n",
        "\n",
        "# Plot cost history for both models\n",
        "fig = graphing.scatter_2D(df, label_x=\"number of iterations\", label_y=\"cost\", title=\"Training Cost vs Iterations\", label_colour=\"Model\")\n",
        "fig.update_traces(mode='lines')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This plots clearly shows that using a standardized dataset allowed our model to converge much faster. Reaching the lowest cost and finding the optimal weights required a much smaller number of iterations.\n",
        "\n",
        "This is very important when you are developing a new model, as it allows you to iterate quicker, but also when your model is deployed to a production environment, as it will require less compute time for training and costing less than a \"slow\" model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "In this exercise we covered the following concepts:\n",
        "\n",
        "- _Feature scalaing_ techniques are used to improve the efficiency of training models\n",
        "- How to add a standardized feature to a dataset\n",
        "- How to visualize standardized features and compare them to their original values\n",
        "\n",
        "Finally, we compared the performance of models before and after using standardized features, using plots to visualize the improvements\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "conda-env-py38_default-py"
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "29ba88fc74c30cfb08fb6ce3b25c2ccd724cd11e96a643650e6c772fb9859a2d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
